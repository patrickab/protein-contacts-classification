{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QiAHkyDdV8-t"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-12 21:17:56.572796: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-09-12 21:17:56.587094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-12 21:17:56.605389: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-12 21:17:56.610540: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-12 21:17:56.622941: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-12 21:17:58.181185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from biopandas.pdb import PandasPdb\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from Bio.PDB import DSSP, HSExposureCB, PPBuilder, is_aa, NeighborSearch\n",
        "from Bio.PDB.MMCIFParser import MMCIFParser\n",
        "from Bio.SeqUtils import seq1\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB, ComplementNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from timeit import default_timer as timer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import matthews_corrcoef, balanced_accuracy_score, average_precision_score, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nWqgNFSup2mP"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "current_directory = os.getcwd()\n",
        "path_ring = current_directory + \"/data/features_ring/\"\n",
        "path_pdb = current_directory + \"/data/pdb_files/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "g9CpTg4Kuz53",
        "outputId": "590ce7c2-5612-4e7f-eb6d-6b06cab80ed5"
      },
      "outputs": [],
      "source": [
        "dfs = []\n",
        "for filename in os.listdir(path_ring):\n",
        "    dfs.append(pd.read_csv(path_ring + filename, sep='\\t'))\n",
        "df = pd.concat(dfs)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "y = df['Interaction'].astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23o46QQlKUgz"
      },
      "source": [
        "# Add Feature: CA-CA Distances between source & target residues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "collapsed": true,
        "id": "LMWui1FIKRqX",
        "outputId": "02e4c776-79dc-45e2-85b2-622093894cae"
      },
      "outputs": [],
      "source": [
        "from Bio import PDB\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "\n",
        "parser = PDB.PDBParser(QUIET=True)\n",
        "\n",
        "\n",
        "def get_residue_distance(pdb_id, s_resi, t_resi, s_ch, t_ch, pdb_file_path):\n",
        "    \"\"\"Calculates CA-CA distance between two residues in a PDB file\"\"\"\n",
        "\n",
        "    structure = parser.get_structure(pdb_id, pdb_file_path)\n",
        "    model = structure[0]\n",
        "\n",
        "\n",
        "    try: # locate source- & target-chains\n",
        "        s_chain = model[s_ch]\n",
        "        t_chain = model[t_ch]\n",
        "    except KeyError:\n",
        "        raise ValueError(f\"Chain {s_ch} or {t_ch} not found in structure {pdb_id}\")\n",
        "\n",
        "\n",
        "    try: # locate source- & target-residues\n",
        "        s_residue = s_chain[s_resi]\n",
        "        t_residue = t_chain[t_resi]\n",
        "    except KeyError:\n",
        "        raise ValueError(f\"Residue {s_resi} or {t_resi} not found in chains {s_ch} or {t_ch}\")\n",
        "\n",
        "\n",
        "    try: # locate alpha carbons\n",
        "        s_ca = s_residue['CA']\n",
        "        t_ca = t_residue['CA']\n",
        "    except KeyError:\n",
        "        raise ValueError(f\"Alpha-carbon not found in residue {s_resi} or {t_resi}\")\n",
        "    \n",
        "\n",
        "    s_ca_coord = s_ca.get_coord()\n",
        "    t_ca_coord = t_ca.get_coord()\n",
        "\n",
        "    distance = np.linalg.norm(s_ca_coord - t_ca_coord)\n",
        "\n",
        "    return distance\n",
        "\n",
        "\n",
        "def process_row(index, row, pdb_directory):\n",
        "\n",
        "    pdb_id = row['pdb_id']\n",
        "    s_resi = row['s_resi']\n",
        "    t_resi = row['t_resi']\n",
        "    s_ch = row['s_ch']\n",
        "    t_ch = row['t_ch']\n",
        "\n",
        "    pdb_file_path = os.path.join(pdb_directory, f'{pdb_id}.pdb')\n",
        "\n",
        "    if not os.path.isfile(pdb_file_path):\n",
        "        print(f\"File {pdb_file_path} does not exist.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        distance = get_residue_distance(pdb_id, s_resi, t_resi, s_ch, t_ch, pdb_file_path)\n",
        "        return distance\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdb_id} (row {index}): {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def calculate_distances_parallel(df, pdb_directory, n_jobs=-1):\n",
        "    # Use Parallel to process each row in the dataframe in parallel\n",
        "    ca_distances = Parallel(n_jobs=n_jobs)(\n",
        "        delayed(process_row)(index, row, pdb_directory) for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Rows\")\n",
        "    )\n",
        "    \n",
        "    # Add the result to the dataframe\n",
        "    df['CA_CA_distance'] = ca_distances\n",
        "    return df\n",
        "\n",
        "if not os.path.exists(current_directory + '/data/df_data.pkl'):\n",
        "    pdb_directory = path_pdb\n",
        "    df = calculate_distances_parallel(df, pdb_directory, n_jobs=-1)\n",
        "else:\n",
        "    df = pd.read_pickle(current_directory + '/data/df_data.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Add Feature: Sequence Neighbors (left/right) Aminoacid Type "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Bio import PDB\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "import os\n",
        "\n",
        "def compute_residue_names(pdb_id, s_ch, s_resi, t_ch, t_resi, path_pdb):\n",
        "    pdb_file = path_pdb + f\"{pdb_id}.pdb\"\n",
        "    if not os.path.isfile(pdb_file):\n",
        "        return None, None, None, None\n",
        "    \n",
        "    structure = PDB.PDBParser(QUIET=True).get_structure(pdb_id, pdb_file)\n",
        "\n",
        "    s_resn_prev, s_resn_next, t_resn_prev, t_resn_next = None, None, None, None\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                if chain.id == s_ch and residue.id[1] == s_resi - 1:\n",
        "                    s_resn_prev = residue.resname\n",
        "                if chain.id == s_ch and residue.id[1] == s_resi + 1:\n",
        "                    s_resn_next = residue.resname\n",
        "                if chain.id == t_ch and residue.id[1] == t_resi - 1:\n",
        "                    t_resn_prev = residue.resname\n",
        "                if chain.id == t_ch and residue.id[1] == t_resi + 1:\n",
        "                    t_resn_next = residue.resname\n",
        "\n",
        "    return s_resn_prev, s_resn_next, t_resn_prev, t_resn_next\n",
        "\n",
        "\n",
        "def process_row(row, path_pdb):\n",
        "    pdb_id = row['pdb_id']\n",
        "    s_ch = row['s_ch']\n",
        "    t_ch = row['t_ch']\n",
        "    s_resi = row['s_resi']\n",
        "    t_resi = row['t_resi']\n",
        "\n",
        "    return compute_residue_names(pdb_id, s_ch, s_resi, t_ch, t_resi, path_pdb)\n",
        "\n",
        "\n",
        "def process_dataset(df, path_pdb):\n",
        "\n",
        "    results = Parallel(n_jobs=-1)(\n",
        "        delayed(process_row)(row, path_pdb) for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Dataset\")\n",
        "    )\n",
        "\n",
        "    # Extract the results and add them as new columns\n",
        "    prev_s_resn_list, next_s_resn_list, prev_t_resn_list, next_t_resn_list = zip(*results)\n",
        "\n",
        "    df['prev_s_resn'] = prev_s_resn_list\n",
        "    df['next_s_resn'] = next_s_resn_list\n",
        "    df['prev_t_resn'] = prev_t_resn_list\n",
        "    df['next_t_resn'] = next_t_resn_list\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "if not os.path.exists(current_directory + '/data/df_data.pkl'):\n",
        "    df = process_dataset(df, path_pdb)\n",
        "else:\n",
        "    df = pd.read_pickle(current_directory + '/data/df_data.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Add Feature: Neighbors in 3D Space with sequence_separtion=6 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing rows: 100%|██████████| 100/100 [00:06<00:00, 14.69it/s]\n",
            "/tmp/ipykernel_27892/758256625.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['s_resn_neighbour'] = s_resn_neighbours_list\n",
            "/tmp/ipykernel_27892/758256625.py:101: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['t_resn_neighbour'] = t_resn_neighbours_list\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from Bio import PDB\n",
        "from tqdm import tqdm\n",
        "from Bio.PDB import PDBParser, NeighborSearch\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "three_to_one_letter = {\n",
        "    'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C',\n",
        "    'GLU': 'E', 'GLN': 'Q', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
        "    'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P',\n",
        "    'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V'\n",
        "}\n",
        "\n",
        "parser = PDB.PDBParser(QUIET=True)\n",
        "\n",
        "def compute_residue_names(pdb_id, s_ch, s_resi, t_ch, t_resi):\n",
        "\n",
        "    pdb_file = os.path.join(path_pdb, f'{pdb_id}.pdb')\n",
        "    structure = parser.get_structure(pdb_id, pdb_file)\n",
        "    \n",
        "    source_residue = structure[0][s_ch][s_resi]\n",
        "    target_residue = structure[0][t_ch][t_resi]\n",
        "\n",
        "    all_atoms = list(structure.get_atoms())  # Search across the entire structure\n",
        "    ns = NeighborSearch(all_atoms)\n",
        "\n",
        "    # Residues within 8.0 Å distance\n",
        "    contacts = ns.search_all(8.0, level=\"R\")\n",
        "\n",
        "    # Exclude contacts with sequence separation <= 6\n",
        "    filtered_contacts = []\n",
        "    for res1, res2 in contacts:\n",
        "\n",
        "        is_amino_acid_1 = is_aa(res1)\n",
        "        is_amino_acid_2 = is_aa(res2)\n",
        "\n",
        "        if is_amino_acid_1 and is_amino_acid_2:\n",
        "            res1_id = res1.get_id()[1]\n",
        "            res2_id = res2.get_id()[1]\n",
        "\n",
        "            if abs(res1_id - res2_id) > 6:\n",
        "                filtered_contacts.append((res1, res2))\n",
        "\n",
        "    # Extract coordinates\n",
        "    source_coords = np.array([atom.coord for atom in source_residue.get_atoms()])\n",
        "    target_coords = np.array([atom.coord for atom in target_residue.get_atoms()])\n",
        "\n",
        "    min_distance_s, min_distance_t = float('inf'), float('inf')\n",
        "    s_resn_neighbour, t_resn_neighbour = None, None\n",
        "\n",
        "    # Process filtered contacts to find the closest residues\n",
        "    for residue1, residue2 in filtered_contacts:\n",
        "        if residue1 == target_residue or residue2 == target_residue:\n",
        "            other_residue = residue2 if residue1 == target_residue else residue1\n",
        "            other_coords = np.array([atom.coord for atom in other_residue.get_atoms()])\n",
        "            distances = np.linalg.norm(target_coords[:, np.newaxis] - other_coords, axis=-1)\n",
        "            min_distance = np.min(distances)\n",
        "\n",
        "            if min_distance < min_distance_t:\n",
        "                min_distance_t = min_distance\n",
        "                t_resn_neighbour = other_residue\n",
        "\n",
        "        if residue1 == source_residue or residue2 == source_residue:\n",
        "            other_residue = residue2 if residue1 == source_residue else residue1\n",
        "            other_coords = np.array([atom.coord for atom in other_residue.get_atoms()])\n",
        "            distances = np.linalg.norm(source_coords[:, np.newaxis] - other_coords, axis=-1)\n",
        "            min_distance = np.min(distances)\n",
        "\n",
        "            if min_distance < min_distance_s:\n",
        "                min_distance_s = min_distance\n",
        "                s_resn_neighbour = other_residue\n",
        "\n",
        "    return (s_resn_neighbour.get_resname(),\n",
        "            t_resn_neighbour.get_resname())\n",
        "\n",
        "\n",
        "def process_row(row):\n",
        "    pdb_id = row['pdb_id']\n",
        "    s_ch = row['s_ch']\n",
        "    t_ch = row['t_ch']\n",
        "    s_resi = row['s_resi']\n",
        "    t_resi = row['t_resi']\n",
        "\n",
        "    s_resn_neighbour, t_resn_neighbour = compute_residue_names(pdb_id, s_ch, s_resi, t_ch, t_resi)\n",
        "    \n",
        "    s_resn_neighbour = three_to_one_letter.get(s_resn_neighbour, s_resn_neighbour)\n",
        "    t_resn_neighbour = three_to_one_letter.get(t_resn_neighbour, t_resn_neighbour)\n",
        "    \n",
        "    return s_resn_neighbour, t_resn_neighbour\n",
        "\n",
        "\n",
        "def process_dataset(df, n_jobs=-1):\n",
        "    results = Parallel(n_jobs=n_jobs)(\n",
        "        delayed(process_row)(row) for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\")\n",
        "    )\n",
        "\n",
        "    s_resn_neighbours_list, t_resn_neighbours_list = zip(*results)\n",
        "    df['s_resn_neighbour'] = s_resn_neighbours_list\n",
        "    df['t_resn_neighbour'] = t_resn_neighbours_list\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "dfh = process_dataset(df.head(100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pdb_id</th>\n",
              "      <th>s_ch</th>\n",
              "      <th>s_resi</th>\n",
              "      <th>s_ins</th>\n",
              "      <th>s_resn</th>\n",
              "      <th>s_ss8</th>\n",
              "      <th>s_rsa</th>\n",
              "      <th>s_up</th>\n",
              "      <th>s_down</th>\n",
              "      <th>s_phi</th>\n",
              "      <th>...</th>\n",
              "      <th>t_ss3</th>\n",
              "      <th>t_a1</th>\n",
              "      <th>t_a2</th>\n",
              "      <th>t_a3</th>\n",
              "      <th>t_a4</th>\n",
              "      <th>t_a5</th>\n",
              "      <th>Interaction</th>\n",
              "      <th>CA_CA_distance</th>\n",
              "      <th>s_resn_neighbour</th>\n",
              "      <th>t_resn_neighbour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3m7l</td>\n",
              "      <td>A</td>\n",
              "      <td>123</td>\n",
              "      <td></td>\n",
              "      <td>R</td>\n",
              "      <td>H</td>\n",
              "      <td>0.032</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-1.747</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.019</td>\n",
              "      <td>-0.987</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.912</td>\n",
              "      <td>VDW</td>\n",
              "      <td>6.722287</td>\n",
              "      <td>Y</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3m7l</td>\n",
              "      <td>A</td>\n",
              "      <td>104</td>\n",
              "      <td></td>\n",
              "      <td>I</td>\n",
              "      <td>H</td>\n",
              "      <td>0.485</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-1.124</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.019</td>\n",
              "      <td>-0.987</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.912</td>\n",
              "      <td>HBOND</td>\n",
              "      <td>6.391156</td>\n",
              "      <td>L</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3m7l</td>\n",
              "      <td>A</td>\n",
              "      <td>104</td>\n",
              "      <td></td>\n",
              "      <td>I</td>\n",
              "      <td>H</td>\n",
              "      <td>0.485</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-1.124</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.019</td>\n",
              "      <td>-0.987</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.912</td>\n",
              "      <td>VDW</td>\n",
              "      <td>6.391156</td>\n",
              "      <td>L</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3m7l</td>\n",
              "      <td>A</td>\n",
              "      <td>139</td>\n",
              "      <td></td>\n",
              "      <td>H</td>\n",
              "      <td>-</td>\n",
              "      <td>0.049</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>-2.085</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.006</td>\n",
              "      <td>-0.590</td>\n",
              "      <td>1.891</td>\n",
              "      <td>-0.397</td>\n",
              "      <td>0.412</td>\n",
              "      <td>HBOND</td>\n",
              "      <td>5.929388</td>\n",
              "      <td>V</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3m7l</td>\n",
              "      <td>A</td>\n",
              "      <td>139</td>\n",
              "      <td></td>\n",
              "      <td>H</td>\n",
              "      <td>-</td>\n",
              "      <td>0.049</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>-2.085</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.006</td>\n",
              "      <td>-0.590</td>\n",
              "      <td>1.891</td>\n",
              "      <td>-0.397</td>\n",
              "      <td>0.412</td>\n",
              "      <td>VDW</td>\n",
              "      <td>5.929388</td>\n",
              "      <td>V</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>3m7l</td>\n",
              "      <td>A</td>\n",
              "      <td>52</td>\n",
              "      <td></td>\n",
              "      <td>W</td>\n",
              "      <td>H</td>\n",
              "      <td>0.137</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-1.006</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.239</td>\n",
              "      <td>-0.547</td>\n",
              "      <td>2.131</td>\n",
              "      <td>0.393</td>\n",
              "      <td>0.816</td>\n",
              "      <td>HBOND</td>\n",
              "      <td>5.940588</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>3m7l</td>\n",
              "      <td>A</td>\n",
              "      <td>52</td>\n",
              "      <td></td>\n",
              "      <td>W</td>\n",
              "      <td>H</td>\n",
              "      <td>0.137</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-1.006</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.239</td>\n",
              "      <td>-0.547</td>\n",
              "      <td>2.131</td>\n",
              "      <td>0.393</td>\n",
              "      <td>0.816</td>\n",
              "      <td>VDW</td>\n",
              "      <td>5.940588</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>3m7l</td>\n",
              "      <td>A</td>\n",
              "      <td>120</td>\n",
              "      <td></td>\n",
              "      <td>S</td>\n",
              "      <td>H</td>\n",
              "      <td>0.146</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-1.168</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.337</td>\n",
              "      <td>-0.279</td>\n",
              "      <td>-0.544</td>\n",
              "      <td>1.242</td>\n",
              "      <td>-1.262</td>\n",
              "      <td>HBOND</td>\n",
              "      <td>4.774477</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>3m7l</td>\n",
              "      <td>A</td>\n",
              "      <td>242</td>\n",
              "      <td></td>\n",
              "      <td>L</td>\n",
              "      <td>H</td>\n",
              "      <td>0.506</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-1.073</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.006</td>\n",
              "      <td>-0.590</td>\n",
              "      <td>1.891</td>\n",
              "      <td>-0.397</td>\n",
              "      <td>0.412</td>\n",
              "      <td>HBOND</td>\n",
              "      <td>5.086136</td>\n",
              "      <td>F</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>3m7l</td>\n",
              "      <td>A</td>\n",
              "      <td>227</td>\n",
              "      <td></td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>0.000</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-1.044</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>-0.595</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.672</td>\n",
              "      <td>-2.128</td>\n",
              "      <td>-0.184</td>\n",
              "      <td>HBOND</td>\n",
              "      <td>6.259705</td>\n",
              "      <td>F</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    pdb_id s_ch  s_resi s_ins s_resn s_ss8  s_rsa  s_up  s_down  s_phi  ...  \\\n",
              "0     3m7l    A     123            R     H  0.032  19.0    10.0 -1.747  ...   \n",
              "1     3m7l    A     104            I     H  0.485   9.0    11.0 -1.124  ...   \n",
              "2     3m7l    A     104            I     H  0.485   9.0    11.0 -1.124  ...   \n",
              "4     3m7l    A     139            H     -  0.049  20.0    18.0 -2.085  ...   \n",
              "5     3m7l    A     139            H     -  0.049  20.0    18.0 -2.085  ...   \n",
              "..     ...  ...     ...   ...    ...   ...    ...   ...     ...    ...  ...   \n",
              "141   3m7l    A      52            W     H  0.137  21.0    12.0 -1.006  ...   \n",
              "142   3m7l    A      52            W     H  0.137  21.0    12.0 -1.006  ...   \n",
              "143   3m7l    A     120            S     H  0.146  18.0    15.0 -1.168  ...   \n",
              "145   3m7l    A     242            L     H  0.506   5.0    13.0 -1.073  ...   \n",
              "147   3m7l    A     227            A     H  0.000  18.0    14.0 -1.044  ...   \n",
              "\n",
              "     t_ss3   t_a1   t_a2   t_a3   t_a4   t_a5  Interaction CA_CA_distance  \\\n",
              "0        H -1.019 -0.987 -1.505  1.266 -0.912          VDW       6.722287   \n",
              "1        H -1.019 -0.987 -1.505  1.266 -0.912        HBOND       6.391156   \n",
              "2        H -1.019 -0.987 -1.505  1.266 -0.912          VDW       6.391156   \n",
              "4        H -1.006 -0.590  1.891 -0.397  0.412        HBOND       5.929388   \n",
              "5        H -1.006 -0.590  1.891 -0.397  0.412          VDW       5.929388   \n",
              "..     ...    ...    ...    ...    ...    ...          ...            ...   \n",
              "141      H -1.239 -0.547  2.131  0.393  0.816        HBOND       5.940588   \n",
              "142      H -1.239 -0.547  2.131  0.393  0.816          VDW       5.940588   \n",
              "143      H -1.337 -0.279 -0.544  1.242 -1.262        HBOND       4.774477   \n",
              "145      H -1.006 -0.590  1.891 -0.397  0.412        HBOND       5.086136   \n",
              "147      H -0.595  0.009  0.672 -2.128 -0.184        HBOND       6.259705   \n",
              "\n",
              "     s_resn_neighbour t_resn_neighbour  \n",
              "0                   Y                F  \n",
              "1                   L                T  \n",
              "2                   L                T  \n",
              "4                   V                F  \n",
              "5                   V                F  \n",
              "..                ...              ...  \n",
              "141                 T                F  \n",
              "142                 T                F  \n",
              "143                 P                P  \n",
              "145                 F                L  \n",
              "147                 F                S  \n",
              "\n",
              "[100 rows x 37 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsaIajMHMEyM",
        "outputId": "fbac0f4a-5d4b-4560-cea5-5a59c065e279"
      },
      "outputs": [],
      "source": [
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "def encode_object_columns(df):\n",
        "    label_encoder = LabelEncoder()\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype == 'object':\n",
        "            df[column] = df[column].astype(str)\n",
        "            df[column] = label_encoder.fit_transform(df[column])\n",
        "    return df\n",
        "\n",
        "df = encode_object_columns(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPYNNbasSyEO"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['Interaction'])\n",
        "y = df['Interaction']\n",
        "\n",
        "y = to_categorical(y, num_classes=10)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "J-ItyEjPTo8P",
        "outputId": "520f8971-7104-4f11-92b9-d09443bf9353"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample a subset of the data\n",
        "sample_size = 50000\n",
        "df_sample = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "X_sample = df_sample.drop(columns=['Interaction'])\n",
        "y_sample = df_sample['Interaction']\n",
        "\n",
        "# Convert labels to one-hot encoding if necessary and then back to labels for Random Forest\n",
        "y_sample = pd.get_dummies(y_sample)  # One-hot encode if needed\n",
        "y_sample_labels = y_sample.values.argmax(axis=1)  # Convert back to labels\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=50, max_depth=20, random_state=42)  # Reduced parameters\n",
        "rf.fit(X_sample, y_sample_labels)\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.bar(range(X_sample.shape[1]), importances[indices], align=\"center\")\n",
        "plt.xticks(range(X_sample.shape[1]), X_sample.columns[indices], rotation=90)\n",
        "plt.xlim([-1, X_sample.shape[1]])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j4aflZcSgjn"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['Interaction', 't_ss3', \"s_ss3\", \"t_ins\", \"s_ins\" ])\n",
        "y = df['Interaction']\n",
        "\n",
        "y = to_categorical(y, num_classes=10) # One-hot encode the labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Handle Imbalanced Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBObwIc6DYc_"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "y_train_labels = np.argmax(y_train, axis=1)\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
        "class_weight_dict = dict(enumerate(class_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A-SqBliFJLjv",
        "outputId": "0ef7559e-91ff-4de2-9b38-0d2fd483ed3c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and first hidden layer\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Third hidden layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fourth hidden layer\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Implement early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Define K-Fold cross-validator\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Store scores for each fold\n",
        "fold_accuracies = []\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Create a new model instance for each fold\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Early stopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_fold, y_train_fold,\n",
        "                        validation_data=(X_val_fold, y_val_fold),\n",
        "                        epochs=50,\n",
        "                        batch_size=32,\n",
        "                        class_weight=class_weight_dict,\n",
        "                        callbacks=[early_stopping],\n",
        "                        verbose=0)  # Set verbose to 1 for detailed output\n",
        "\n",
        "   # Predict the labels for the validation fold\n",
        "    y_val_pred = np.argmax(model.predict(X_val_fold), axis=1)\n",
        "    y_val_true = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    # Compute balanced accuracy for the current fold\n",
        "    balanced_acc = balanced_accuracy_score(y_val_true, y_val_pred)\n",
        "    print(f\"Balanced accuracy for current fold: {balanced_acc:.4f}\")\n",
        "\n",
        "    fold_accuracies.append(balanced_acc)\n",
        "\n",
        "# Calculate and print the average balanced accuracy across all folds\n",
        "average_balanced_accuracy = np.mean(fold_accuracies)\n",
        "print(f\"Average balanced accuracy across all folds: {average_balanced_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToCjxj1tJ9nK",
        "outputId": "b4a06c53-98fa-4014-b335-95abc6ab182e"
      },
      "outputs": [],
      "source": [
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "mcc = matthews_corrcoef(y_true, y_pred)\n",
        "balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "avg_precision = average_precision_score(y_test, y_pred_proba, average='macro')\n",
        "\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
        "print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "print(f\"Average Precision Score: {avg_precision:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
